{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tecton Virtual Hands-On Lab\n",
        "![lab1](/files/tables/lab1.jpg)"
      ],
      "metadata": {
        "id": "U5aMbxSF1qgC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "940bdbe5-2963-4678-ac12-9a5b5d43b926",
          "showTitle": false,
          "title": ""
        },
        "id": "-ugalH5KmDcq"
      },
      "outputs": [],
      "source": [
        "# import tecton and other libraries\n",
        "import os\n",
        "import tecton\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "tecton.set_credentials(tecton_api_key=dbutils.secrets.get(scope='tecton-lab-2', key='TECTON_API_KEY'),tecton_url=\"https://lab.tecton.ai/api\")\n",
        "ws = tecton.get_workspace('prod')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Sources\n",
        "\n",
        "First we will be creating a connection to Tecton from a batch data source. Once a data source is defined in Tecton, it can be used to build features. The code below shows allows Tecton to read data on demonstrating example transactions. It was been added to your workspace already."
      ],
      "metadata": {
        "id": "NOlL7aG51wSH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "05e2a1ef-603d-4b99-9b07-166cc4632c40",
          "showTitle": false,
          "title": ""
        },
        "id": "LeEx8RtQmDct"
      },
      "source": [
        "```\n",
        "from tecton import BatchSource, FileConfig\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "transactions = BatchSource(\n",
        "    name=\"transactions\",\n",
        "    batch_config=FileConfig(\n",
        "        uri=\"s3://tecton.ai.public/tutorials/fraud_demo/transactions/data.pq\",\n",
        "        file_format=\"parquet\",\n",
        "        timestamp_field=\"timestamp\",\n",
        "    ),\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e607088d-f9a5-4e7d-a742-91fa90de857e",
          "showTitle": false,
          "title": ""
        },
        "id": "BBuEZfOfmDct"
      },
      "source": [
        "Use the example above to create a customers BatchSource with\n",
        "* The **name** as ***customers***\n",
        "* **uri** being ***s3://tecton.ai.public/tutorials/fraud_demo/customers/data.pq***\n",
        "* The same **file_format** as above\n",
        "* The **timestamp_field** of ***signup_timestamp***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b5fa00fb-91f7-4200-b80f-f7d1c9a561a7",
          "showTitle": false,
          "title": ""
        },
        "id": "ZAwNHYBQmDct"
      },
      "outputs": [],
      "source": [
        "\n",
        "## add import statements here\n",
        "\n",
        "\n",
        "## add BatchSource definition here\n",
        "customers = BatchSource()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features Views\n",
        "With some data sources defined, we can build features views off them. Feature views are used by Tecton to define how, when, and where it will materialize features. Feature views can be either Batch FeatureViews, Stream Feature Views, or On-Demand Feature Views. Below, is an example of an incomplete Batch Feature View."
      ],
      "metadata": {
        "id": "HK-Ouvy013mo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "14de98f2-0dc4-4a9c-a196-d596ced51c2e",
          "showTitle": false,
          "title": ""
        },
        "id": "SsXQRGoBmDcu"
      },
      "source": [
        "```\n",
        "from tecton import Entity, BatchSource, FileConfig, batch_feature_view, FilteredSource\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
        "\n",
        "@batch_feature_view(\n",
        "    sources=[FilteredSource(customers)],\n",
        "    entities=[user],\n",
        "    mode=\"spark_sql\",\n",
        "    batch_schedule=timedelta(days=1),\n",
        "    ttl=timedelta(days=3650),\n",
        ")\n",
        "def user_credit_card_issuer(customers):\n",
        "    return f\"\"\"\n",
        "        SELECT\n",
        "            user_id,\n",
        "            signup_timestamp,\n",
        "            CASE SUBSTRING(CAST(cc_num AS STRING), 0, 1)\n",
        "                WHEN '4' THEN 'Visa'\n",
        "                ELSE 'other'\n",
        "            END as credit_card_issuer\n",
        "        FROM\n",
        "            {customers}\n",
        "        \"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "7f33447e-c332-488b-8bb1-959b49c9be73",
          "showTitle": false,
          "title": ""
        },
        "id": "JUmOF0V2mDcu"
      },
      "source": [
        "In the empty cell below, redefine the feature to include the cases when a **'5'** appears to be ***'MasterCard'*** and when **'6'** appears to be ***'Discover'***\n",
        "\n",
        "Afterwords, running the validate() cell will ensure that Tecton can reach the specified data source and it is has the proper schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2f19bec2-2c42-4ffc-94ab-b0a00a1b4f29",
          "showTitle": false,
          "title": ""
        },
        "id": "FJLF_6UbmDcv"
      },
      "outputs": [],
      "source": [
        "#define feature view with new defintion here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c2f36399-8688-4ba6-b618-c2c4dc8fe5bb",
          "showTitle": false,
          "title": ""
        },
        "id": "LDbXFpzAmDcv"
      },
      "outputs": [],
      "source": [
        "user_credit_card_issuer.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b9769ac6-0df5-44a9-bcad-fbb17927e632",
          "showTitle": false,
          "title": ""
        },
        "id": "TTP90pqRmDcw"
      },
      "source": [
        "# Feature Views with Aggregations\n",
        "Aggregations can simplify implementations of common powerful features. For this feature view, we will perform a number of different aggregations to show the average and total transaction amounts for each user of given time periods. We will be utilizing just two, but Tecton provides [many different aggregations.](https://docs.tecton.ai/docs/sdk-reference/time-window-aggregation-functions#docusaurus_skipToContent_fallback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e801ed51-0fc8-4df5-bcc9-50b604b261d1",
          "showTitle": false,
          "title": ""
        },
        "id": "e1z1fxFNmDcw"
      },
      "source": [
        "```\n",
        "from tecton import Entity, BatchSource, FileConfig, batch_feature_view, Aggregation\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "transactions = ws.get_data_source(\"transactions\")\n",
        "\n",
        "\n",
        "@batch_feature_view(\n",
        "    description=\"User transaction metrics over 1, 3 and 7 days\",\n",
        "    sources=[transactions],\n",
        "    entities=[user],\n",
        "    mode=\"spark_sql\",\n",
        "    aggregation_interval=timedelta(days=10),\n",
        "    aggregations=[\n",
        "        Aggregation(function=\"mean\", column=\"amt\", time_window=timedelta(days=1)),\n",
        "        Aggregation(function=\"mean\", column=\"amt\", time_window=timedelta(days=30)),\n",
        "        Aggregation(function=\"mean\", column=\"amt\", time_window=timedelta(days=365)),\n",
        "        Aggregation(function=\"max\", column=\"transaction\", time_window=timedelta(days=1)),\n",
        "        Aggregation(function=\"max\", column=\"transaction\", time_window=timedelta(days=30)),\n",
        "        Aggregation(function=\"max\", column=\"transaction\", time_window=timedelta(days=365)),\n",
        "    ],\n",
        "    online=True,\n",
        "    offline=True,\n",
        "    feature_start_time=datetime(2023, 1, 1),\n",
        "    batch_schedule=timedelta(days=1),\n",
        ")\n",
        "def user_transaction_metrics_1(transactions):\n",
        "    return f\"\"\"\n",
        "        SELECT user_id, timestamp, amt, 1 as transaction\n",
        "        FROM {transactions}\n",
        "        \"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "04e89830-ade6-4155-a829-2eb74aabc08b",
          "showTitle": false,
          "title": ""
        },
        "id": "dbfon80-mDcw"
      },
      "source": [
        "In the empty cell below, create a batch_feature_view with the following changes:\n",
        "\n",
        "* Change the **aggregation_interval** from *10 days* to ***days=1***.\n",
        "  * This will match our batch_schedule\n",
        "* Change the **1 day**, **30 days** and **365 days** intervals to ***days=1***, ***days=3***, ***days=7***\n",
        "* Change the aggregations using **max** to use ***count***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7ee5112e-a7fc-4234-aa0e-32448d8f7f3c",
          "showTitle": false,
          "title": ""
        },
        "id": "6fu0FtF3mDcw"
      },
      "outputs": [],
      "source": [
        "#define feature with updated aggregations here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fc9a7f18-96bf-4701-b3e7-d240ae23f9a7",
          "showTitle": false,
          "title": ""
        },
        "id": "hpu2lOMTmDcx"
      },
      "outputs": [],
      "source": [
        "user_transaction_metrics_1.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0607cb41-654b-4061-89a8-83154bc0c4fc",
          "showTitle": false,
          "title": ""
        },
        "id": "aBebUdwfmDcx"
      },
      "source": [
        "# On-Demand Feature Views\n",
        "An On-Demand Feature View is used to run row-level, request-time transformations on data from Request Sources, Batch Feature Views, or Stream Feature Views. Unlike Batch and Stream Feature Views, On-Demand Feature Views do not precompute and materialize data to the Feature Store, but instead run transformations both online and offline at the time of the request.\n",
        "\n",
        "We can build on top of the feature view we just made to compare historical values to requests happening at transaction time. Run the cell below, which defines the input and output Tecton should expect at transaction time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1a8c19e6-e2ba-487a-9e98-ea0611e5dc0e",
          "showTitle": false,
          "title": ""
        },
        "id": "NGShJtAFmDcx"
      },
      "outputs": [],
      "source": [
        "from tecton import RequestSource\n",
        "from tecton.types import Float64, Field, Bool\n",
        "\n",
        "request_schema = [Field('amt', Float64)]\n",
        "transaction_request = RequestSource(schema=request_schema)\n",
        "output_schema = [Field('transaction_amount_is_higher_than_7d_average', Bool)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f9f39870-cd07-45a8-96a8-2ffb570c5d4c",
          "showTitle": false,
          "title": ""
        },
        "id": "UT2JRt1bmDcx"
      },
      "source": [
        "We can use this new source to create an on_demand_feature_view below.\n",
        "\n",
        "The @on_demand_feature_view\n",
        "* will take in 2 **sources** as a list - the incoming **transaction_request** and the previously built feature **user_transaction_metrics_1**.\n",
        "* The **mode** will be ***'python'***\n",
        "* The **schema** will be the **output_schema** that was just defined.\n",
        "\n",
        "We will define the incoming transaction amount being higher that the current 7 day average for a particular user as follows:\n",
        "```{python}\n",
        "amount_mean = 0 if user_transaction_metrics_1['amt_mean_7d_1d'] is None else user_transaction_metrics_1['amt_mean_7d_1d']\n",
        "    return {'transaction_amount_is_higher_than_7d_average': transaction_request['amt'] > amount_mean}\n",
        "```\n",
        "\n",
        "Use this as the feature definition and validate the on_demand_feature_view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1a3662fa-91f7-4e9f-8853-15119183f02c",
          "showTitle": false,
          "title": ""
        },
        "id": "_hG4uGNgmDcx"
      },
      "outputs": [],
      "source": [
        "from tecton import on_demand_feature_view\n",
        "from tecton import RequestSource\n",
        "from tecton.types import Float64, Field, Bool\n",
        "\n",
        "user_transaction_metrics = ws.get_feature_view('user_transaction_metrics')\n",
        "\n",
        "@on_demand_feature_view(\n",
        "   #fill in with parameters described above\n",
        "\n",
        ")\n",
        "def transaction_amount_is_higher_than_7d_average(transaction_request, user_transaction_metrics):\n",
        "    #definition goes here\n",
        "\n",
        "\n",
        "transaction_amount_is_higher_than_7d_average.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Services\n",
        "A Feature Service refernces a set of features which are exposed as an API. It's generally recommended that each machine learning model has an associated Feature Service. We will create the a Feature Service with 3 of the Feature Views we just built:\n",
        "\n",
        "* user_credit_card_issuer\n",
        "* user_transaction_metrics_1[['amt_mean_7d_1d']]\n",
        "* transaction_amount_is_higher_than_7d_average"
      ],
      "metadata": {
        "id": "F0HwWCX51_jg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8409e6ca-1462-445f-aa2e-62646ac756c7",
          "showTitle": false,
          "title": ""
        },
        "id": "IB3IuC_wmDcy"
      },
      "outputs": [],
      "source": [
        "from tecton import FeatureService\n",
        "\n",
        "lab_fs = FeatureService(\n",
        "  name = 'lab_fs',\n",
        "  features = [\n",
        "    #add features here\n",
        "\n",
        "  ]\n",
        ")\n",
        "\n",
        "lab_fs.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c1900640-9190-4e74-9de1-7499d3dfa5d7",
          "showTitle": false,
          "title": ""
        },
        "id": "lSs53AUemDcx"
      },
      "source": [
        "## go to [lab.tecton.ai](https://lab.tecton.ai)\n",
        "Tecton automatically builds on top of pre-existing features to materialize this one as new data comes in, orchestrates it together automatically with a the other feature views, and creates and runs the spark and python jobs necessary to keep every feature view updated\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Retrieval and model training\n",
        "Now that all the features are defined in a feature set, we can generate data to send to machine learning models for training and serving.\n",
        "\n",
        "get_historical_features() allows us to generate training examples from an offline store, in the second cell below, while the request call to Tecton's API generates features from an online store for faster retrieval at serving time.\n",
        "\n",
        "We can retrieve a large data set with high throughput from the offline store to train a machine learning model"
      ],
      "metadata": {
        "id": "0exNCEvO2MbR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "576f67b1-1474-4438-a3c1-a21265fc96a7",
          "showTitle": false,
          "title": ""
        },
        "id": "Y-xi94vv4Gkl"
      },
      "outputs": [],
      "source": [
        "from tecton import FeatureService\n",
        "\n",
        "training_events = (\n",
        "    spark.read.parquet(\"s3://tecton.ai.public/tutorials/fraud_demo/transactions/\")\n",
        "    .select(\"user_id\", \"timestamp\", \"amt\", \"is_fraud\")\n",
        "    .limit(1000)\n",
        ")\n",
        "\n",
        "fraud_detection_feature_service = FeatureService(\n",
        "    name=\"fraud_detection_feature_service\", features=[user_transaction_metrics_1]\n",
        ")\n",
        "fraud_detection_feature_service.validate()\n",
        "\n",
        "training_data = fraud_detection_feature_service.get_historical_features(training_events).to_pandas().fillna(0)\n",
        "display(training_data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "54d0770f-af24-44a8-af2a-a19dc074b8a6",
          "showTitle": false,
          "title": ""
        },
        "id": "D-DXy0CD4Gkl"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "df = training_data.drop([\"user_id\", \"timestamp\", \"amt\"], axis=1)\n",
        "\n",
        "X = df.drop(\"is_fraud\", axis=1)\n",
        "y = df[\"is_fraud\"]\n",
        "X = X.reindex(sorted(X.columns), axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "num_cols = X_train.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "num_pipe = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
        "\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"N/A\"), OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        ")\n",
        "\n",
        "full_pipe = ColumnTransformer([(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)])\n",
        "\n",
        "model = make_pipeline(full_pipe, LogisticRegression(max_iter=1000, random_state=42))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_predict, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Retrieval and real-time inference\n",
        "Features are retrieved from the online store with HTTP requests for low latency. The cell below constructs an example request.\n",
        "\n",
        "We can pull features from an online store to send to a model in real-time, and get a prediction on whether or not a transaction is fraudulent before it happens"
      ],
      "metadata": {
        "id": "GUyb-Chl2RXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0d371718-db19-4556-82b6-b7a9b496f080",
          "showTitle": false,
          "title": ""
        },
        "id": "DEU7kBGn4Gkl"
      },
      "outputs": [],
      "source": [
        "import requests, json\n",
        "\n",
        "\n",
        "def get_online_feature_data(user_id, amt):\n",
        "    headers = {\"Authorization\": \"Tecton-key \" + dbutils.secrets.get(scope='tecton-lab-2', key='TECTON_API_KEY')}\n",
        "\n",
        "    request_data = f\"\"\"{{\n",
        "        \"params\": {{\n",
        "            \"feature_service_name\": \"fraud_detection_feature_service\",\n",
        "            \"join_key_map\": {{\"user_id\": \"{user_id}\"}},\n",
        "            \"metadata_options\": {{\"include_names\": true}},\n",
        "            \"request_context_map\": {{\"amt\": {amt}}},\n",
        "            \"workspace_name\": \"prod\"\n",
        "        }}\n",
        "    }}\"\"\"\n",
        "\n",
        "    online_feature_data = requests.request(\n",
        "        method=\"POST\",\n",
        "        headers=headers,\n",
        "        url=f\"https://lab.tecton.ai/api/v1/feature-service/get-features\",\n",
        "        data=request_data,\n",
        "    )\n",
        "\n",
        "    online_feature_data_json = json.loads(online_feature_data.text)\n",
        "\n",
        "    return online_feature_data_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "85c7347e-9c4e-463c-8e13-6a1ab87cb112",
          "showTitle": false,
          "title": ""
        },
        "id": "dzgHVl0Q4Gkl"
      },
      "outputs": [],
      "source": [
        "user_id = \"user_502567604689\"\n",
        "\n",
        "feature_data = get_online_feature_data(user_id, 200)\n",
        "\n",
        "if \"result\" not in feature_data:\n",
        "    print(\"Feature data is not materialized\")\n",
        "else:\n",
        "    print(feature_data[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "42b8d3bb-4b7d-4dac-9c5d-a458ead0e9c0",
          "showTitle": false,
          "title": ""
        },
        "id": "2GDneMB64Gkl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_prediction_from_model(feature_data):\n",
        "    columns = [f[\"name\"].replace(\".\", \"__\") for f in feature_data[\"metadata\"][\"features\"][2:]]\n",
        "    columns = [f[:24] + \"_1\" + f[24:] for f in columns]\n",
        "    data = [feature_data[\"result\"][\"features\"][2:]]\n",
        "\n",
        "    features = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    if model.predict(features):\n",
        "        return \"Transaction denied.\"\n",
        "    else:\n",
        "        return \"Transaction accepted.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ce507155-b1f2-4a62-a5e1-2be4cf88c78d",
          "showTitle": false,
          "title": ""
        },
        "id": "90z2p0Uw4Gkm"
      },
      "outputs": [],
      "source": [
        "user_id = \"user_502567604689\"\n",
        "\n",
        "online_feature_data = get_online_feature_data(user_id, 20)\n",
        "prediction = get_prediction_from_model(online_feature_data)\n",
        "\n",
        "print(prediction)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "LAB",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}